{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of plugins: 691\n",
      "Number of blacklisted plugins: 34\n",
      "Number of plugins in openplugins_info: 681\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "import requests\n",
    "from openplugincore import OpenPlugin\n",
    "import openai\n",
    "import logging\n",
    "from typing import Any, Callable, Dict, List, Optional, TypedDict\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "openai.api_key = OPENAI_API_KEY\n",
    "\n",
    "# filter out \"Attempting to load an OpenAPI 3.0.0 spec...\" from log\n",
    "with open('migration.log', 'r') as file:\n",
    "    lines = file.readlines()\n",
    "filtered_lines = [line for line in lines if 'your undesired string' not in line]\n",
    "with open('migration.log', 'w') as file:\n",
    "    file.writelines(filtered_lines)\n",
    "\n",
    "class OpenPluginInfoBase(TypedDict):\n",
    "    namespace: str\n",
    "    image: Optional[str]\n",
    "    description_for_human: Optional[str]\n",
    "    description_for_model: str\n",
    "    domain: str\n",
    "    openapi_url: str\n",
    "\n",
    "class OpenPluginInfoInit(OpenPluginInfoBase, TypedDict):\n",
    "    whitelisted: bool\n",
    "\n",
    "class OpenPluginInfoStimulated(OpenPluginInfoInit, TypedDict):\n",
    "    stimulated: bool\n",
    "    stimulous_prompt: Optional[str]\n",
    "\n",
    "class OpenPluginInfo(OpenPluginInfoStimulated, TypedDict):\n",
    "    status: str\n",
    "\n",
    "OpenPluginsInfo = Dict[str, OpenPluginInfo]\n",
    "\n",
    "logging.basicConfig(filename='migration.log', level=logging.INFO, format='%(asctime)s %(message)s')\n",
    "\n",
    "openplugin_classes: Dict[str, OpenPlugin] = {}\n",
    "\n",
    "# 1. Assign `all_plugins.json` to variable `all_plugins`\n",
    "pypi_client_path = 'openai_res.json'\n",
    "with open(pypi_client_path, 'r', encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "try:\n",
    "    json_content = ''.join(lines)\n",
    "    openai_res = json.loads(json_content)\n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"JSONDecodeError: {e}\")\n",
    "print(f\"Number of plugins: {len(openai_res)}\")\n",
    "\n",
    "# 2. Create `blacklist_list` dict\n",
    "if os.path.exists('blacklist.json'):\n",
    "    with open('blacklist.json', 'r', encoding='utf-8') as f:\n",
    "        blacklist = json.load(f)\n",
    "else:\n",
    "    blacklist = {}\n",
    "    with open('blacklist.json', 'w', encoding='utf-8') as f:\n",
    "        json.dump(blacklist, f, indent=2)\n",
    "def aggregate_items(json_object):\n",
    "    aggregate_list = []\n",
    "    for key in json_object:\n",
    "        aggregate_list.extend(json_object[key])\n",
    "    return aggregate_list\n",
    "blacklist_list = aggregate_items(blacklist)\n",
    "print(f\"Number of blacklisted plugins: {len(blacklist_list)}\")\n",
    "\n",
    "# 3. Assign `plugins_info.json` to variable `plugins_info`\n",
    "if os.path.exists('openplugins_info.json'):\n",
    "    with open('openplugins_info.json', 'r', encoding='utf-8') as f:\n",
    "        openplugins_info: dict = json.load(f)\n",
    "else:\n",
    "    openplugins_info = {}\n",
    "    with open('openplugins_info.json', 'w', encoding='utf-8') as f:\n",
    "        json.dump(openplugins_info, f, indent=2)\n",
    "        \n",
    "print(f\"Number of plugins in openplugins_info: {len(openplugins_info)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_res_ex = {\n",
    "  \"id\": \"plugin-027a8b9d-7f54-42d3-8a04-1b6391997cf8\",\n",
    "  \"domain\": \"plugin-3c56b9d4c8a6465998395f28b6a445b2-jexkai4vea-uc.a.run.app\",\n",
    "  \"namespace\": \"Ai_PDF\",\n",
    "  \"status\": \"approved\",\n",
    "  \"manifest\": {\n",
    "    \"schema_version\": \"v1\",\n",
    "    \"name_for_model\": \"Ai_PDF\",\n",
    "    \"name_for_human\": \"Ai PDF\",\n",
    "    \"description_for_model\": \"Provide a URL to a PDF and search the document. Break the user question in multiple semantic search queries and calls as needed. Think step by step.\",\n",
    "    \"description_for_human\": \"Super-fast, interactive chats with PDFs of any size, complete with page references for fact checking.\",\n",
    "    \"auth\": {\n",
    "      \"type\": \"none\"\n",
    "    },\n",
    "    \"api\": {\n",
    "      \"type\": \"openapi\",\n",
    "      \"url\": \"https://plugin-3c56b9d4c8a6465998395f28b6a445b2-jexkai4vea-uc.a.run.app/openapi.yaml\"\n",
    "    },\n",
    "    \"logo_url\": \"https://plugin-3c56b9d4c8a6465998395f28b6a445b2-jexkai4vea-uc.a.run.app/logo.png\",\n",
    "    \"contact_email\": \"support@promptapps.ai\",\n",
    "    \"legal_info_url\": \"https://plugin-3c56b9d4c8a6465998395f28b6a445b2-jexkai4vea-uc.a.run.app/legal.html\"\n",
    "  },\n",
    "  \"oauth_client_id\": None,\n",
    "  \"user_settings\": {\n",
    "    \"is_installed\": True,\n",
    "    \"is_authenticated\": True\n",
    "  },\n",
    "  \"categories\": [\n",
    "    {\n",
    "      \"id\": \"most_popular\",\n",
    "      \"title\": \"Most popular\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\n",
    "# openai_res_ex = {\n",
    "#   \"id\": \"plugin-988f53b4-5d81-4703-983a-38b6dac4b8ac\",\n",
    "#   \"domain\": \"chat-web3-plugin.alchemy.com\",\n",
    "#   \"namespace\": \"Alchemy\",\n",
    "#   \"status\": \"approved\",\n",
    "#   \"manifest\": {\n",
    "#     \"schema_version\": \"v1\",\n",
    "#     \"name_for_model\": \"Alchemy\",\n",
    "#     \"name_for_human\": \"Alchemy\",\n",
    "#     \"description_for_model\": \"Request real-time blockchain data for chains like Ethereum, Polygon, Arbitrum and Optimism through natural language.\",\n",
    "#     \"description_for_human\": \"Request real-time blockchain data for chains like Ethereum, Polygon, Arbitrum and Optimism through natural language.\",\n",
    "#     \"auth\": {\n",
    "#       \"type\": \"service_http\",\n",
    "#       \"instructions\": \"\",\n",
    "#       \"authorization_type\": \"bearer\",\n",
    "#       \"verification_tokens\": {\n",
    "#         \"openai\": \"f9cd21497220486789fa94c7a129a040\"\n",
    "#       }\n",
    "#     },\n",
    "#     \"api\": {\n",
    "#       \"type\": \"openapi\",\n",
    "#       \"url\": \"https://chat-web3-plugin.alchemy.com/openapi.yaml\"\n",
    "#     },\n",
    "#     \"logo_url\": \"https://chat-web3-plugin.alchemy.com/logo.png\",\n",
    "#     \"contact_email\": \"support@alchemy.com\",\n",
    "#     \"legal_info_url\": \"https://www.alchemy.com/policies/terms\"\n",
    "#   },\n",
    "#   \"oauth_client_id\": None,\n",
    "#   \"user_settings\": {\n",
    "#     \"is_installed\": False,\n",
    "#     \"is_authenticated\": True\n",
    "#   },\n",
    "#   \"categories\": [\n",
    "#     {\n",
    "#       \"id\": \"newly_added\",\n",
    "#       \"title\": \"New\"\n",
    "#     }\n",
    "#   ]\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'namespace': 'Ai_PDF',\n",
       " 'image': 'https://plugin-3c56b9d4c8a6465998395f28b6a445b2-jexkai4vea-uc.a.run.app/logo.png',\n",
       " 'description_for_human': 'Super-fast, interactive chats with PDFs of any size, complete with page references for fact checking.',\n",
       " 'description_for_model': 'Provide a URL to a PDF and search the document. Break the user question in multiple semantic search queries and calls as needed. Think step by step.',\n",
       " 'domain': 'plugin-3c56b9d4c8a6465998395f28b6a445b2-jexkai4vea-uc.a.run.app',\n",
       " 'openapi_url': 'https://plugin-3c56b9d4c8a6465998395f28b6a445b2-jexkai4vea-uc.a.run.app/openapi.yaml',\n",
       " 'auth': False,\n",
       " 'blacklisted': False}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def generate_base_opinfo(openplugins_info: OpenPluginsInfo, blacklist_list: List[str],  openai_res_plugin: Any) -> OpenPluginInfoBase:\n",
    "    namespace = openai_res_plugin['namespace']\n",
    "    openplugin_info = {\n",
    "        **openplugins_info.get(namespace, {}),\n",
    "        'namespace': namespace,\n",
    "        'image': openai_res_plugin['manifest'].get('logo_url', None),\n",
    "        'description_for_human': openai_res_plugin['manifest'].get('description_for_human', None),\n",
    "        'description_for_model': openai_res_plugin['manifest']['description_for_model'],\n",
    "        'domain': openai_res_plugin['domain'],\n",
    "        'openapi_url': openai_res_plugin['manifest']['api']['url']\n",
    "    }\n",
    "    # auth check\n",
    "    if openai_res_plugin['manifest'].get('auth', {}).get('type', None) == 'none':\n",
    "        openplugin_info['auth'] = False\n",
    "    else:\n",
    "        openplugin_info['auth'] = True\n",
    "    # blacklisted check\n",
    "    if openai_res_plugin['namespace'] in blacklist_list:\n",
    "        openplugin_info['blacklisted'] = True\n",
    "    else:\n",
    "        openplugin_info['blacklisted'] = False\n",
    "    openplugins_info[namespace] = openplugin_info\n",
    "\n",
    "    return openplugin_info\n",
    "\n",
    "first = generate_base_opinfo(openplugins_info, blacklist_list, openai_res_ex)\n",
    "first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'namespace': 'Ai_PDF',\n",
       " 'image': 'https://plugin-3c56b9d4c8a6465998395f28b6a445b2-jexkai4vea-uc.a.run.app/logo.png',\n",
       " 'description_for_human': 'Super-fast, interactive chats with PDFs of any size, complete with page references for fact checking.',\n",
       " 'description_for_model': 'Provide a URL to a PDF and search the document. Break the user question in multiple semantic search queries and calls as needed. Think step by step.',\n",
       " 'domain': 'plugin-3c56b9d4c8a6465998395f28b6a445b2-jexkai4vea-uc.a.run.app',\n",
       " 'openapi_url': 'https://plugin-3c56b9d4c8a6465998395f28b6a445b2-jexkai4vea-uc.a.run.app/openapi.yaml',\n",
       " 'auth': False,\n",
       " 'blacklisted': False,\n",
       " 'whitelisted': True}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_fetch_and_parse(openplugins_info: OpenPluginsInfo, openplugin_classes: Dict[str, OpenPlugin], openai_res_plugin: Any) -> OpenPluginInfoInit: \n",
    "    namespace = openai_res_plugin['namespace']\n",
    "    openplugin_info = openplugins_info[namespace]\n",
    "    root_url = \"https://\" + openplugin_info['domain']\n",
    "    try:\n",
    "        openplugin_classes[namespace] = OpenPlugin(openai_api_key=OPENAI_API_KEY, root_url=root_url)\n",
    "        logging.info(f\"{namespace} Whitelist Success\")\n",
    "        openplugin_info['whitelisted'] = True\n",
    "    except Exception as e:\n",
    "        logging.error(f\"{namespace} Whitelist Error: {e}\")\n",
    "        openplugin_info['whitelisted'] = False\n",
    "\n",
    "    return openplugin_info\n",
    "\n",
    "second = test_fetch_and_parse(openplugins_info, openplugin_classes, openai_res_ex)\n",
    "second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'namespace': 'Ai_PDF',\n",
       " 'image': 'https://plugin-3c56b9d4c8a6465998395f28b6a445b2-jexkai4vea-uc.a.run.app/logo.png',\n",
       " 'description_for_human': 'Super-fast, interactive chats with PDFs of any size, complete with page references for fact checking.',\n",
       " 'description_for_model': 'Provide a URL to a PDF and search the document. Break the user question in multiple semantic search queries and calls as needed. Think step by step.',\n",
       " 'domain': 'plugin-3c56b9d4c8a6465998395f28b6a445b2-jexkai4vea-uc.a.run.app',\n",
       " 'openapi_url': 'https://plugin-3c56b9d4c8a6465998395f28b6a445b2-jexkai4vea-uc.a.run.app/openapi.yaml',\n",
       " 'auth': False,\n",
       " 'blacklisted': False,\n",
       " 'whitelisted': True,\n",
       " 'stimulous_prompt': 'Search for information in a PDF document and provide page references for fact checking. Use a PDF of any size, such as `https://example.com/document.pdf`. Make sure the search is fast and interactive.',\n",
       " 'stimulated': True}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_stimulate(openplugins_info: OpenPluginsInfo, openplugin_classes: Dict[str, OpenPlugin], openai_res_plugin: Any) -> OpenPluginInfoStimulated:\n",
    "    namespace = openai_res_plugin['namespace']\n",
    "    openplugin_info = openplugins_info[namespace]\n",
    "    openplugin_class = openplugin_classes[namespace]\n",
    "    try:\n",
    "        generate_stimulation_prompt_prompt = {\n",
    "            \"prompt\": f\"\"\"\n",
    "            Please create a prompt that will trigger an model's plugin with the human description delimited by driple backticks.\n",
    "            If necessary also look at the model description also delimited by triple backticks.\n",
    "            Please do not ask anything from the AI you should provide all the information it needs in the prompt.\n",
    "            You should not be ambiguous or open ended in your prompt use specific examples.\n",
    "            Do not simply restate the description.\n",
    "            Human description:\n",
    "            ```\n",
    "            {openplugin_info[\"description_for_human\"]}\n",
    "            ```\n",
    "            Model description:\n",
    "            ```\n",
    "            {openplugin_info[\"description_for_model\"]}\n",
    "            ```\n",
    "            \"\"\",\n",
    "            \"function\": {\n",
    "            \"name\": \"stimulous_prompt_generation\",\n",
    "            \"description\": \"\"\"\n",
    "            Generates a natural language phrase to that triggeres the AI plugin.\n",
    "            If approriate the phrase should include an example item/url (https://github.com/)/text/ect. even if you are not sure if it is real its ok to make it up.\n",
    "            \"\"\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                \"stimulous_prompt\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The stimulous phrase to trigger the AI plugin\"\n",
    "                },\n",
    "                },\n",
    "                \"required\": [\"stimulous_prompt\"]\n",
    "            }\n",
    "            }\n",
    "        }\n",
    "        generation = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo-0613\",\n",
    "            temperature=0.7,\n",
    "            messages=[{\"role\": \"user\", \"content\": generate_stimulation_prompt_prompt[\"prompt\"]}],\n",
    "            functions=[generate_stimulation_prompt_prompt[\"function\"]],\n",
    "            function_call={\"name\": \"stimulous_prompt_generation\"}\n",
    "        )\n",
    "        json_arguments = json.loads(generation[\"choices\"][0][\"message\"][\"function_call\"][\"arguments\"])\n",
    "        openplugin_info[\"stimulous_prompt\"] = json_arguments[\"stimulous_prompt\"]\n",
    "        openplugin_class.fetch_plugin(\n",
    "            prompt=openplugin_info[\"stimulous_prompt\"],\n",
    "            model=\"gpt-3.5-turbo-0613\",\n",
    "            temperature=0,\n",
    "        )\n",
    "        openplugin_info[\"stimulated\"] = True\n",
    "        logging.info(f\"{namespace} Stimulate Success\")\n",
    "    except Exception as e:\n",
    "        openplugin_info[\"stimulous_prompt\"] = openplugin_info.get(\"stimulous_prompt\", None)\n",
    "        openplugin_info[\"stimulated\"] = False\n",
    "        logging.error(f\"{namespace} Stimulate Error: {e}\")\n",
    "    return openplugin_info\n",
    "\n",
    "third = test_stimulate(openplugins_info, openplugin_classes, openai_res_ex)\n",
    "third"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'namespace': 'Ai_PDF',\n",
       " 'image': 'https://plugin-3c56b9d4c8a6465998395f28b6a445b2-jexkai4vea-uc.a.run.app/logo.png',\n",
       " 'description_for_human': 'Super-fast, interactive chats with PDFs of any size, complete with page references for fact checking.',\n",
       " 'description_for_model': 'Provide a URL to a PDF and search the document. Break the user question in multiple semantic search queries and calls as needed. Think step by step.',\n",
       " 'domain': 'plugin-3c56b9d4c8a6465998395f28b6a445b2-jexkai4vea-uc.a.run.app',\n",
       " 'openapi_url': 'https://plugin-3c56b9d4c8a6465998395f28b6a445b2-jexkai4vea-uc.a.run.app/openapi.yaml',\n",
       " 'auth': False,\n",
       " 'blacklisted': False,\n",
       " 'whitelisted': True,\n",
       " 'stimulous_prompt': 'Search for information in a PDF document and provide page references for fact checking. Use a PDF of any size, such as `https://example.com/document.pdf`. Make sure the search is fast and interactive.',\n",
       " 'stimulated': True,\n",
       " 'status': 'supported'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def assign_status(openplugins_info: OpenPluginsInfo, openai_res_plugin: Any) -> OpenPluginInfo:\n",
    "    namespace = openai_res_plugin['namespace']\n",
    "    openplugin_info = openplugins_info[namespace]\n",
    "    openplugin_info[\"status\"] = \"unsupported\"\n",
    "    if not openplugin_info[\"auth\"] and not openplugin_info[\"blacklisted\"] and openplugin_info[\"whitelisted\"]:\n",
    "        openplugin_info[\"status\"] = \"tentative\"\n",
    "    if openplugin_info[\"stimulous_prompt\"] and openplugin_info[\"stimulated\"]:\n",
    "        openplugin_info[\"status\"] = \"supported\"\n",
    "\n",
    "    return openplugin_info\n",
    "\n",
    "fourth = assign_status(openplugins_info, openai_res_ex)\n",
    "fourth    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_openplugin(openplugins_info: OpenPluginsInfo, openai_res_plugin: Any) -> None:\n",
    "    # save to openplugins_info.json\n",
    "    if not os.path.exists('openplugins_info.json'):\n",
    "        with open('openplugins_info.json', 'w', encoding='utf-8') as f:\n",
    "            json.dump(openplugins_info, f, indent=2)\n",
    "    else:\n",
    "        with open('openplugins_info.json', 'w', encoding='utf-8') as f:\n",
    "            json.dump(openplugins_info, f, indent=2)\n",
    "    \n",
    "    # save to openplugins.json\n",
    "    namespace = openai_res_plugin['namespace']\n",
    "    openplugin_info = openplugins_info[namespace]\n",
    "    if (openplugin_info[\"status\"] == \"supported\" or openplugin_info[\"status\"] == \"tentative\"):\n",
    "        with open('openplugins.json', 'r', encoding='utf-8') as f:\n",
    "            openplugins = json.load(f)\n",
    "        openplugins[namespace] = \"https://\" + openplugin_info[\"domain\"]\n",
    "        with open('openplugins.json', 'w', encoding='utf-8') as f:\n",
    "            json.dump(openplugins, f, indent=2)\n",
    "        logging.info(f\"{namespace} Save to openplugins Success\")\n",
    "    else:\n",
    "        logging.info(f\"{namespace} Save to openplugins Skipped\")\n",
    "fifth = save_openplugin(openplugins_info, openai_res_ex)\n",
    "fifth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_pluginsmd(openplugins_info: OpenPluginsInfo) -> None:\n",
    "    current_dir = os.getcwd()\n",
    "    root_dir = os.path.abspath(os.path.join(current_dir, os.pardir, os.pardir))\n",
    "\n",
    "    # Create the file path for plugins.md\n",
    "    pluginsmd_path = os.path.join(root_dir, 'PLUGINS.md')\n",
    "    plugins_md = \"\"\"# Plugins\n",
    "Available plugins for OpenPlugin\n",
    "Status:\n",
    "- `tentative`: passed basic tests (may work)\n",
    "- `supported`: passed complete prompt tests (should work)\n",
    "\n",
    "| Image | Namespace | Status | Description | Description for model |\n",
    "| --- | --- | --- | --- | --- |\n",
    "\"\"\"\n",
    "\n",
    "    def escape_special_markdown_chars(text):\n",
    "        # Characters to escape: \\ ` * _ { } [ ] ( ) # + !\n",
    "        special_chars = r'\\\\|`|\\*|_|{|}|\\[|\\]|\\(|\\)|#|\\+|!'\n",
    "        return re.sub(special_chars, lambda match: '\\\\' + match.group(), text)\n",
    "\n",
    "    def remove_line_breaks(text):\n",
    "        return text.replace('\\n', ' ').replace('\\r', '')\n",
    "\n",
    "    # create two lists of plugins one supported_plugins and one tentative_plugins\n",
    "    supported_plugins = []\n",
    "    tentative_plugins = []\n",
    "    for _namespace, openplugin_info in openplugins_info.items():\n",
    "        if openplugin_info[\"status\"] == \"tentative\":\n",
    "            tentative_plugins.append(openplugin_info)\n",
    "        if openplugin_info[\"status\"] == \"supported\":\n",
    "            supported_plugins.append(openplugin_info)\n",
    "    # now sort the lists by their namespace keys considering that each plugin is a dict of {namespace: str, ...}\n",
    "    supported_plugins.sort(key=lambda x: x[\"namespace\"])\n",
    "    tentative_plugins.sort(key=lambda x: x[\"namespace\"])\n",
    "    # aggragate the lists so that supported_plugins is first and tentative_plugins is second \n",
    "    ordered_openplugins_info = supported_plugins + tentative_plugins\n",
    "\n",
    "    for openplugin_info in ordered_openplugins_info:\n",
    "            if openplugin_info[\"image\"]:\n",
    "                image = escape_special_markdown_chars(openplugin_info[\"image\"])\n",
    "            else:\n",
    "                image = escape_special_markdown_chars(\"https://i.imgur.com/L3giCRt.png\")\n",
    "            namespace = escape_special_markdown_chars(openplugin_info[\"namespace\"])\n",
    "            status = escape_special_markdown_chars(openplugin_info[\"status\"])\n",
    "            description = escape_special_markdown_chars(remove_line_breaks(remove_line_breaks(openplugin_info[\"description_for_human\"])))\n",
    "            description_for_model = escape_special_markdown_chars(remove_line_breaks(openplugin_info[\"description_for_model\"]))\n",
    "            plugins_md += f\"| ![{namespace} Logo]({image}) | {namespace} | {status} | {description} | {description_for_model} |\\n\"\n",
    "\n",
    "    with open(pluginsmd_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(plugins_md)\n",
    "\n",
    "sixth = save_to_pluginsmd(openplugins_info, openai_res_ex)\n",
    "sixth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'namespace': 'Ai_PDF',\n",
       " 'image': 'https://plugin-3c56b9d4c8a6465998395f28b6a445b2-jexkai4vea-uc.a.run.app/logo.png',\n",
       " 'description_for_human': 'Super-fast, interactive chats with PDFs of any size, complete with page references for fact checking.',\n",
       " 'description_for_model': 'Provide a URL to a PDF and search the document. Break the user question in multiple semantic search queries and calls as needed. Think step by step.',\n",
       " 'domain': 'plugin-3c56b9d4c8a6465998395f28b6a445b2-jexkai4vea-uc.a.run.app',\n",
       " 'openapi_url': 'https://plugin-3c56b9d4c8a6465998395f28b6a445b2-jexkai4vea-uc.a.run.app/openapi.yaml',\n",
       " 'auth': False,\n",
       " 'blacklisted': False,\n",
       " 'whitelisted': True,\n",
       " 'stimulous_prompt': \"Search for information in a PDF document and provide page references for fact checking. For example, search for the term 'artificial intelligence' in a PDF document about machine learning.\",\n",
       " 'stimulated': False,\n",
       " 'status': 'tentative'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def classify_plugin(openplugins_info: OpenPluginsInfo, openai_res_plugin: Any) -> OpenPluginInfo:\n",
    "    # first\n",
    "    openplugin_info = generate_base_opinfo(openplugins_info, blacklist_list, openai_res_plugin)\n",
    "    # second\n",
    "    if openplugin_info[\"auth\"] or openplugin_info[\"blacklisted\"] or openplugin_info.get(\"whitelisted\", None) == False:\n",
    "        openplugin_info[\"whitelisted\"] = False\n",
    "        openplugin_info[\"stimulous_prompt\"] = None\n",
    "        openplugin_info[\"stimulated\"] = False\n",
    "    else:\n",
    "        openplugin_info = test_fetch_and_parse(openplugins_info, openplugin_classes, openai_res_plugin)\n",
    "        if openplugin_info[\"whitelisted\"]:\n",
    "            openplugin_info = test_stimulate(openplugins_info, openplugin_classes, openai_res_plugin)\n",
    "        else:\n",
    "            openplugin_info[\"stimulous_prompt\"] = None\n",
    "            openplugin_info[\"stimulated\"] = False\n",
    "    openplugin_info = assign_status(openplugins_info, openai_res_plugin)\n",
    "    return openplugin_info\n",
    "composite = classify_plugin(openplugins_info, openai_res_ex)\n",
    "composite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup_log() -> None:\n",
    "    with open('migration.log', 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    filtered_lines = [line for line in lines if 'Attempting to load an OpenAPI 3.' not in line]\n",
    "    with open('migration.log', 'w') as file:\n",
    "        file.writelines(filtered_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 of 691\n",
      "20 of 691\n",
      "40 of 691\n",
      "60 of 691\n",
      "80 of 691\n",
      "100 of 691\n",
      "120 of 691\n",
      "140 of 691\n",
      "160 of 691\n",
      "180 of 691\n",
      "200 of 691\n",
      "220 of 691\n",
      "240 of 691\n",
      "260 of 691\n",
      "280 of 691\n",
      "300 of 691\n",
      "320 of 691\n",
      "340 of 691\n",
      "360 of 691\n",
      "380 of 691\n",
      "400 of 691\n",
      "420 of 691\n",
      "440 of 691\n",
      "460 of 691\n",
      "480 of 691\n",
      "500 of 691\n",
      "520 of 691\n",
      "540 of 691\n",
      "560 of 691\n",
      "580 of 691\n",
      "600 of 691\n",
      "620 of 691\n",
      "640 of 691\n",
      "660 of 691\n",
      "680 of 691\n"
     ]
    }
   ],
   "source": [
    "# iterate trhough all items in the openai_res.json array\n",
    "start_idx = 0\n",
    "for idx, openai_res_plugin in enumerate(openai_res[start_idx:]):\n",
    "    prorated_idx = idx + start_idx\n",
    "    if prorated_idx % 20 == 0:\n",
    "        print(f\"{prorated_idx} of {len(openai_res)}\")\n",
    "    logging.info(f\"{prorated_idx} Processing {openai_res_plugin['namespace']}\")\n",
    "    openplugin_info = classify_plugin(openplugins_info, openai_res_plugin)\n",
    "    save_openplugin(openplugins_info, openai_res_plugin)\n",
    "    logging.info(f\"{openai_res_plugin['namespace']} Complete\")\n",
    "    cleanup_log()\n",
    "save_to_pluginsmd(openplugins_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "681 total plugins\n",
      "307 plugins with status unsupported\n",
      "197 plugins with status tentative\n",
      "177 plugins with status supported\n",
      "First openplugin info: {\n",
      "  \"namespace\": \"Ai_PDF\",\n",
      "  \"image\": \"https://plugin-3c56b9d4c8a6465998395f28b6a445b2-jexkai4vea-uc.a.run.app/logo.png\",\n",
      "  \"description_for_human\": \"Super-fast, interactive chats with PDFs of any size, complete with page references for fact checking.\",\n",
      "  \"description_for_model\": \"Provide a URL to a PDF and search the document. Break the user question in multiple semantic search queries and calls as needed. Think step by step.\",\n",
      "  \"domain\": \"plugin-3c56b9d4c8a6465998395f28b6a445b2-jexkai4vea-uc.a.run.app\",\n",
      "  \"openapi_url\": \"https://plugin-3c56b9d4c8a6465998395f28b6a445b2-jexkai4vea-uc.a.run.app/openapi.yaml\",\n",
      "  \"auth\": false,\n",
      "  \"blacklisted\": false,\n",
      "  \"whitelisted\": true,\n",
      "  \"stimulous_prompt\": \"Search a PDF document and provide the user with super-fast, interactive chats. The PDF can be of any size and should include page references for fact checking. For example, search a PDF document of a scientific research paper and provide the user with relevant information and page numbers for specific concepts or findings.\",\n",
      "  \"stimulated\": false,\n",
      "  \"status\": \"tentative\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "num_unsupported = 0\n",
    "num_tentative = 0\n",
    "num_supported = 0\n",
    "for namespace, openplugin_info in openplugins_info.items():\n",
    "    if openplugin_info[\"status\"] == \"unsupported\":\n",
    "        num_unsupported += 1\n",
    "    if openplugin_info[\"status\"] == \"tentative\":\n",
    "        num_tentative += 1\n",
    "    if openplugin_info[\"status\"] == \"supported\":\n",
    "        num_supported += 1\n",
    "first_openplugin_info = openplugins_info[list(openplugins_info.keys())[0]]\n",
    "print(f\"{len(openplugins_info)} total plugins\\n{num_unsupported} plugins with status unsupported\\n{num_tentative} plugins with status tentative\\n{num_supported} plugins with status supported\\nFirst openplugin info: {json.dumps(first_openplugin_info, indent=2)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envManualTesting",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
